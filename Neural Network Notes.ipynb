{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we want to predict our score on a test (y) based on how many hours we slept and how long we studied (x).\n",
    "Let's set up some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# x = (hours slept/hours studied)\n",
    "X = np.array(([3,5], [5,1], [10,2]), dtype=float)\n",
    "\n",
    "# y = score on test\n",
    "y = np.array(([75], [82], [93]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,   5.],\n",
       "       [  5.,   1.],\n",
       "       [ 10.,   2.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75.],\n",
       "       [ 82.],\n",
       "       [ 93.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a __supervised regression__ problem.\n",
    "\n",
    "* _supervised_: examples have inputs (hours slept/hours studied) and outputs (score)\n",
    "* _regression_:  we are predicting test score, which is a _continuous_ output\n",
    "\n",
    "If we were prediciting a letter grade, it would be a __classification__ problem.\n",
    "\n",
    "Anyway, to solve this problem, we will use an __aritificial neural network__ (ANN).\n",
    "\n",
    "The first problem we have is that the input is in hours, but the output is a score of 100. To make sure our variables are on the same scale, let's divide each variable by the maximum for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 # Max test score is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3,  1. ],\n",
       "       [ 0.5,  0.2],\n",
       "       [ 1. ,  0.4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75],\n",
       "       [ 0.82],\n",
       "       [ 0.93]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What will our network look like? We'll have 2 inputs -- hours of sleep and hours of study, and 1 output -- $\\hat{y}$.\n",
    " \n",
    "We call the output $\\hat{y}$ because it's an estimate of y, but not the same as y.\n",
    "\n",
    "The layers inbetween these inputs and outputs are __hidden layers__.\n",
    "\n",
    "We'll use 1 hidden layer with 3 neurons.\n",
    "\n",
    "<img src=\"images/neuralnet.jpg\" alt=\"\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to store all of our inputs in a matrix called X.\n",
    "\n",
    "Then we'll store all of our weights in a matrix called W<sup>(1)</sup>.\n",
    "\n",
    "Each element in matrix X gets put into the input neurons, multiplied by the weights connected to that neuron and then summed.\n",
    "\n",
    "<img src=\"images/fp1.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "-->\n",
    "\n",
    "<img src=\"images/fp2.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "Then we can just multiply all of these together to get the values for our neurons in our hidden layer. We'll call that resulting matrix Z<sup>(2)</sup>. To clarify, this Z matrix is the result of putting through all of our inputs multiplied by our weights.\n",
    "\n",
    "<img src=\"images/matricesandweights.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "In Z, every entry is a sum of weighted inputs.\n",
    "Z is 3x3:\n",
    "\n",
    "* Row = 1 for each example\n",
    "* Column = 1 for each hidden unit\n",
    "\n",
    "In other words, each column is the values for the three examples for each of the neurons in the hidden layer.\n",
    "Remember, we are putting through all of the data at once.\n",
    "\n",
    "Anyway, this gives us our first formula:\n",
    "\n",
    "__Z<sup>(2)</sup> = XW<sup>(1)</sup>__\n",
    "\n",
    "Now that we have our values for each neuron in the hidden layer, we need to apply our activation function to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUrmLiGSh/wMu/HNySa51rQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5455f8588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For our activation function f, we'lluse sigmoid\n",
    "# Reminder: sigmoid will be close to 0 when -ve, and close to 1 when +ve\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    # Apply sigmoid activation function\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "test_input = np.arange(-6, 6, 0.01)\n",
    "plt.plot(test_input, sigmoid(test_input), linewidth=2)\n",
    "plt.grid(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This gives us our second forward propagation formula:\n",
    "\n",
    "__a<sup>(2)</sup> = f(z<sup>(2)</sup>)__, where f is our sigmoid -- acitivation -- function.\n",
    "\n",
    "a<sup>(2)</sup> will also be a 3x3 matrix -- it's just our matrix Z run through sigmoid.\n",
    "\n",
    "Now, to get our output, we need to multiply that value by our second layer weights, W<sub>(2)</sub>.\n",
    "\n",
    "This gives us our third formula:\n",
    "\n",
    "__Z<sub>(3)</sub> = a<sub>(2)</sub>W<sub>(2)</sub>__\n",
    "\n",
    "<img src=\"images/w2.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "W<sub>(2)</sub> is a 3x1 matrix -- one weight for each synapse.\n",
    "\n",
    "So applying it will give us another 3x1 matrix.\n",
    "\n",
    "Finally, we'll just apply our activation function to that Z<sub>(3)</sub> matrix to get our official estimate.\n",
    "\n",
    "So our last formula is:\n",
    "__$\\hat{y}$ = f(z<sub>(3)</sub>)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a neural network class\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        # Define HyperParameters\n",
    "        # HyperParameters: Define structure and behaviour of our network\n",
    "        # but are not updated as we train the network.\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        # Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, \\\n",
    "                                  self.hiddenLayerSize)\n",
    "        \n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, \\\n",
    "                                  self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Propagate inputs through the network\n",
    "        # Sending through all inputs at once in a matrix is more efficient\n",
    "        self.z2 = np.dot(X, self.W1) # z2 = all inputs * input weights, 3x3 matrix\n",
    "        self.a2 = self.sigmoid(self.z2) # a2 = z2 squished into 0-1\n",
    "        self.z3 = np.dot(self.a2, self.W2) # z3 = z2 * output weights\n",
    "        y_hat = self.sigmoid(self.z3) # y_hat = z3 squished into 0-1\n",
    "        return y_hat\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        # Apply sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3038088 ,  0.34656128, -1.02975353],\n",
       "       [ 1.11114563, -1.38822095, -0.93497135]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07035546],\n",
       "       [ 1.31784677],\n",
       "       [ 0.9372487 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63483297],\n",
       "       [ 0.72806274],\n",
       "       [ 0.69744815]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = network.forward(X)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With random weights, this network will obviously __not__ give good results!\n",
    "\n",
    "We need to train it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "To improve our network, we first need to work out exactly how wrong it is.\n",
    "\n",
    "We do this by using a __cost function__. The higher the result of the cost function, the more wrong our model is.\n",
    "\n",
    "One way to compute a cost function is:\n",
    "\n",
    "1. For every output:\n",
    "2. Work out the difference between the correct value and our result\n",
    "3. Square this value\n",
    "4. Multiply it by 0.5 (why? it will make things simpler apparently)\n",
    "5. Sum all of these values up\n",
    "\n",
    "Formally:\n",
    "\n",
    "$J = \\sum \\frac{1}{2}(y-\\hat{y})^2$\n",
    "\n",
    "So, we want to minimize this cost function to make the network more accurate.\n",
    "\n",
    "_Training a network == Minimizing the cost function_\n",
    "\n",
    "So, how do we minimize the cost function? Well, by changing the weights.\n",
    "Conceptually, this is quite simple -- there must be some combination of weights that will make our cost function as small as possible.\n",
    "\n",
    "<img src=\"images/neural_net_notes/weightchanging.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "Our cost function is an expression in terms of y and $\\hat{y}$, and $\\hat{y}$ was given by our previous equations. Substituting $\\hat{y}$ for the equations in our neural network that gave us $\\hat{y}$, we get:\n",
    "\n",
    "$J = \\sum \\frac{1}{2}(y-f(XW^{(1)})W^{(2)}))^2$\n",
    "\n",
    "Now we want to know, what is the rate of change for J with respect to W. I.e., how does J change when we change W, our weights.\n",
    "\n",
    "Well, remember calculus. This is a derivative. Specifically, since we just consider one weight at a time, it's a partial derivative.\n",
    "\n",
    "$\\frac{dJ}{dW}$\n",
    "\n",
    "Recall that the gradient of a function consists of a vector with all of it's partial derivatives.\n",
    "\n",
    "The gradient has another nice property -- it's the slope of steepest ascent.\n",
    "\n",
    "Therefore, if we take the -ve gradient, we will be going downhill -- descending -- as quickly as possible.\n",
    "\n",
    "So this is where __gradient descent__ comes in:\n",
    "\n",
    "1. Compute the gradient of our function\n",
    "2. Take a small step in the -gradient direction\n",
    "3. Repeat until we've minimized our function\n",
    "\n",
    "One issue is that we might hit a local minima instead of a global minima. This is one reason we square our differences in the cost function -- it tends to give us a parabola, which obviously won't have local minima.\n",
    "\n",
    "Sometimes we can just take our input in batches instead of all at once, and it won't matter if the function is convex or not -- this is stochastic gradient descent (taking input in batches). But for now we'll process all input at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Backpropagation\n",
    "We have 2 sets of weights -- input weights and output weights.\n",
    "\n",
    "We'll calculate the derivative of these weights indiviually.\n",
    "\n",
    "<img src=\"images/neural_net_notes/weightmatrices.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "Let's take $W^{(2)}$ first:\n",
    "\n",
    "$\\frac{\\partial{J}}{\\partial{W^{(2)}}} = \\frac{\\partial{\\sum \\frac{1}{2}(y-\\hat{y})^2}}{\\partial{W^{(2)}}}$\n",
    "\n",
    "(Recall J is the sum of all our error scores.)\n",
    "\n",
    "We can use the sum rule: the derivative of the sum == the sum of the derivatives.\n",
    "\n",
    "So move the sum outside, and just worry about the derivative of the inside expression:\n",
    "\n",
    "$\\frac{\\partial{J}}{\\partial{W^{(2)}}} = \\sum \\frac{\\partial{\\frac{1}{2}(y-\\hat{y})^2}}{\\partial{W^{(2)}}}$\n",
    "\n",
    "Crunching through the derivative with the power rule and then chain rule, we come to:\n",
    "\n",
    "$-(y-\\hat{y})\\frac{\\partial{\\hat{y}}}{\\partial{W^{(2)}}}$\n",
    "\n",
    "-- We need to take the derivative of $\\hat{y}$ with respect to W.\n",
    "\n",
    "Recall that $\\hat{y} = f(Z^{(3)})$ -- y hat is the activation function applied to z3. (z3 was our output from the hidden layer * output weights).\n",
    "\n",
    "So we apply the chain rule again:\n",
    "\n",
    "$-(y-\\hat{y})\\frac{\\partial{\\hat{y}}}{\\partial{Z^{(3)}}}\\frac{\\partial{Z^{(3)}}}{\\partial{W^{(2)}}}$\n",
    "\n",
    "Reminder: we can express the chain rule as the product of derivatives (and in multivariable calculus, we differentiate the function with respect to its X parameter, and then we differentiate the X parameter expression, which may also be a function, for example. Like, we have a function that takes a function as a parameter. What is the derivative? Well, it's the change caused by that inner function to the outer function, and the change caused by the parameter to the inner function on the inner function. Hence you have the two changes -- the two derivatives -- multiplied together). Anyway:\n",
    "\n",
    "$\\frac{\\partial{Z}}{\\partial{X}} = \\frac{\\partial{Z}}{\\partial{Y}}\\frac{\\partial{Y}}{\\partial{X}}$\n",
    "\n",
    "To differentiate $\\hat{y}$ with respect to $Z^{(3)}$, we need need to differentiate our sigmoid function with respect to Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(z):\n",
    "    # Derivative of Sigmoid function\n",
    "    return np.exp(-z)/((1+np.exp(-z))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f546154d30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f545d21240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The derivative will be largest where our function is the steepest\n",
    "test_values = np.arange(-5, 5, 0.01)\n",
    "\n",
    "plt.plot(test_values, sigmoid(test_values), linewidth=2)\n",
    "plt.plot(test_values, sigmoid_prime(test_values), linewidth=2)\n",
    "plt.grid(1)\n",
    "plt.legend(['sigmoid', 'sigmoid_prime'])data:image/png;base64,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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can replace to get:\n",
    "\n",
    "$-(y-\\hat{y})f'({Z^{(3)}})\\frac{\\partial{Z^{(3)}}}{\\partial{W^{(2)}}}$\n",
    "\n",
    "So we need to differentiate $\\frac{\\partial{Z^{(3)}}}{\\partial{W^{(2)}}}$\n",
    "\n",
    "I.e., how does $Z^{(3)}$ change with respect to our second layer of weights -- out weights in the output layer ($W^{(2)}$).\n",
    "\n",
    "Another way to think of gradient descent/backpropagation:\n",
    "\n",
    "1. Calculate a gradient for each example\n",
    "2. Each calculation is like a vote for our gradient to go a certain direction\n",
    "3. The sum/batch gradient basically takes the \"average\" of those gradients and moves in that direction\n",
    "\n",
    "<img src=\"images/neural_net_notes/grad1.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"images/neural_net_notes/grad2.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "Anyway, the derivative is summarized as follows:\n",
    "\n",
    "$\\partial^{(3)} = -(y-\\hat{y})f'(Z^{(3)})$\n",
    "\n",
    "and\n",
    "\n",
    "$\\frac{\\partial{J}}{\\partial{W^{(2)}}} = (a^{(2)})^{T}\\partial^{(3)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a neural network class\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        # Define HyperParameters\n",
    "        # HyperParameters: Define structure and behaviour of our network\n",
    "        # but are not updated as we train the network.\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        # Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, \\\n",
    "                                  self.hiddenLayerSize)\n",
    "        \n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, \\\n",
    "                                  self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Propagate inputs through the network\n",
    "        # Sending through all inputs at once in a matrix is more efficient\n",
    "        self.z2 = np.dot(X, self.W1) # z2 = all inputs * input weights, 3x3 matrix\n",
    "        self.a2 = self.sigmoid(self.z2) # a2 = z2 squished into 0-1\n",
    "        self.z3 = np.dot(self.a2, self.W2) # z3 = z2 * output weights\n",
    "        y_hat = self.sigmoid(self.z3) # y_hat = z3 squished into 0-1\n",
    "        return y_hat\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        # Apply sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    # NEW!\n",
    "    def sigmoid_prime(z):\n",
    "        # Derivative of Sigmoid function\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    # NEW!\n",
    "    def cost_function_prime(self, X, y):\n",
    "        # Compute derivative with respect to W1 and W2\n",
    "        self.y_hat = self.forward(X)\n",
    "        # The first part of the derivative we calculated for changes with respect to W2\n",
    "        delta3 = np.multiply(-(y-self.y_hat), self.sigmoid_prime(self.z3))\n",
    "        # How the error scores change with respect to second layer of weights (W2)\n",
    "        # (transpose of hidden layer * gradient calculated above -- delta3)\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate how our error changes with respect to the first layer of weights, $W^{(1)}$.\n",
    "\n",
    "Now we want to know how $Z^{(3)}$ changes with respect to $a^{(2)}$. This would just be the weight value for that synapse.\n",
    "\n",
    "<img src=\"images/neural_net_notes/z3a2.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "This is represented mathematically by multiplying by $(W^{(2)})^T$. _(why does this transpose method work?)_\n",
    "\n",
    "Anyway, he crunches through the calculus and to represent the change to the error (J) with respect to the first layer of weights (W1), he gets:\n",
    "\n",
    "$\\partial^{(3)} = -(y-\\hat{y})f'(Z^{(3)})$\n",
    "\n",
    "$\\partial^{(2)} = \\partial^{(3)}(W^{(2)})^{T}f'(Z^{(2)})$\n",
    "\n",
    "$\\frac{\\partial{J}}{\\partial{W^{(1)}}} = X^T\\partial^{(2)}$\n",
    "\n",
    "(Recall X is our input layer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a neural network class\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        # Define HyperParameters\n",
    "        # HyperParameters: Define structure and behaviour of our network\n",
    "        # but are not updated as we train the network.\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        # Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, \\\n",
    "                                  self.hiddenLayerSize)\n",
    "        \n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, \\\n",
    "                                  self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Propagate inputs through the network\n",
    "        # Sending through all inputs at once in a matrix is more efficient\n",
    "        self.z2 = np.dot(X, self.W1) # z2 = all inputs * input weights, 3x3 matrix\n",
    "        self.a2 = self.sigmoid(self.z2) # a2 = z2 squished into 0-1\n",
    "        self.z3 = np.dot(self.a2, self.W2) # z3 = z2 * output weights\n",
    "        y_hat = self.sigmoid(self.z3) # y_hat = z3 squished into 0-1\n",
    "        return y_hat\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        # Apply sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    # NEW!\n",
    "    def sigmoid_prime(self, z):\n",
    "        # Derivative of Sigmoid function\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    # NEW!\n",
    "    def cost_function(self, X, y):\n",
    "        # Computer the cost for a given X,y, using current weights\n",
    "        self.y_hat = self.forward(X)\n",
    "        J = 0.5 * sum((y-self.y_hat)**2)\n",
    "        return J\n",
    "    \n",
    "    # NEW!\n",
    "    def cost_function_prime(self, X, y):\n",
    "        # Compute derivative with respect to W1 and W2\n",
    "        self.y_hat = self.forward(X)\n",
    "        \n",
    "        # The first part of the derivative we calculated for changes with respect to W2\n",
    "        delta3 = np.multiply(-(y-self.y_hat), self.sigmoid_prime(self.z3))\n",
    "        \n",
    "        # How the error score changes with respect to second layer of weights (W2)\n",
    "        # (transpose of hidden layer * gradient calculated above -- delta3)\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        # How things change with respect to second layer weights?\n",
    "        delta2 = np.dot(delta3, self.W2.T)*sigmoid_prime(self.z2)\n",
    "        \n",
    "        # How the error score changes with respect to our first layer of weights\n",
    "        dJdW1 = np.dot(X.T, delta2)\n",
    "        \n",
    "        return dJdW1, dJdW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Neural_Network()\n",
    "\n",
    "cost1 = network.cost_function(X, y)\n",
    "\n",
    "dJdW1, dJdW2 = network.cost_function_prime(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02109425,  0.00210368, -0.0093369 ],\n",
       "       [-0.0120667 ,  0.00127888, -0.00698281]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dJdW tells us which way is uphill in our 9D optimization space\n",
    "dJdW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06797576],\n",
       "       [-0.04573993],\n",
       "       [-0.02509696]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJdW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, we just move downhill by some step:\n",
    "step_size = 3\n",
    "\n",
    "network.W1 = network.W1 - step_size*dJdW1\n",
    "network.W2 = network.W2 - step_size*dJdW2\n",
    "cost2 = network.cost_function(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08032818] [ 0.0586503]\n"
     ]
    }
   ],
   "source": [
    "# Compare the costs before/after we stepped down --\n",
    "# we can see the function was reduced.\n",
    "print(cost1, cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do it again:\n",
    "dJdW1, dJdW2 = network.cost_function_prime(X, y)\n",
    "network.W1 = network.W1 - step_size*dJdW1\n",
    "network.W2 = network.W2 - step_size*dJdW2\n",
    "cost3 = network.cost_function(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0586503] [ 0.0448976]\n"
     ]
    }
   ],
   "source": [
    "# Function was reduced again.\n",
    "print(cost2, cost3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we have gradient descent -- calculating a gradient with backpropagation, then moving DOWN to update this gradient, thus making our network more correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical gradient checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since an incorrect derivative/gradient calculation can be hard to detect, it's a good idea to test your gradient function (`cost_function_prime`).\n",
    "\n",
    "This is basically done by checking the gradients using the formal definition of the derivative.\n",
    "\n",
    "This gives you a way to unit test (kinda) your gradient function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "There are a number of issues we have to be careful of when doing gradient descent:\n",
    "\n",
    "1. We get stuck in a local minima\n",
    "2. We may move to slowly and never reach our minima\n",
    "3. We may move to quickly and skip over our minima\n",
    "\n",
    "There are various optimization techniques to help try to avoid these.\n",
    "\n",
    "__BFGS__ is an optimized variation of gradient descent.\n",
    "It estimates the second derivative (curvature) and using this information to make better movements downhill.\n",
    "\n",
    "There is an implementation of BFGS build into `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a neural network class\n",
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        # Define HyperParameters\n",
    "        # HyperParameters: Define structure and behaviour of our network\n",
    "        # but are not updated as we train the network.\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        # Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, \\\n",
    "                                  self.hiddenLayerSize)\n",
    "        \n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, \\\n",
    "                                  self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Propagate inputs through the network\n",
    "        # Sending through all inputs at once in a matrix is more efficient\n",
    "        self.z2 = np.dot(X, self.W1) # z2 = all inputs * input weights, 3x3 matrix\n",
    "        self.a2 = self.sigmoid(self.z2) # a2 = z2 squished into 0-1\n",
    "        self.z3 = np.dot(self.a2, self.W2) # z3 = z2 * output weights\n",
    "        y_hat = self.sigmoid(self.z3) # y_hat = z3 squished into 0-1\n",
    "        return y_hat\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        # Apply sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoid_prime(self, z):\n",
    "        # Derivative of Sigmoid function\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def cost_function(self, X, y):\n",
    "        # Computer the cost for a given X,y, using current weights\n",
    "        self.y_hat = self.forward(X)\n",
    "        J = 0.5 * sum((y-self.y_hat)**2)\n",
    "        return J\n",
    "    \n",
    "    def cost_function_prime(self, X, y):\n",
    "        # Compute derivative with respect to W1 and W2\n",
    "        self.y_hat = self.forward(X)\n",
    "        \n",
    "        # The first part of the derivative we calculated for changes with respect to W2\n",
    "        delta3 = np.multiply(-(y-self.y_hat), self.sigmoid_prime(self.z3))\n",
    "        \n",
    "        # How the error score changes with respect to second layer of weights (W2)\n",
    "        # (transpose of hidden layer * gradient calculated above -- delta3)\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        # How things change with respect to second layer weights?\n",
    "        delta2 = np.dot(delta3, self.W2.T)*sigmoid_prime(self.z2)\n",
    "        \n",
    "        # How the error score changes with respect to our first layer of weights\n",
    "        dJdW1 = np.dot(X.T, delta2)\n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    # Helper functions for interacting with scipy optimize\n",
    "    \n",
    "    # New!\n",
    "    def get_params(self):\n",
    "        # Unroll W1 and W2 into vector\n",
    "        # Reminder: Ravel converts multidimensional array into 1d array\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    # New!\n",
    "    def set_params(self, params):\n",
    "        # Convert 1D arrays to W1 and W2\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    # New!\n",
    "    def compute_gradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.cost_function_prime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        \n",
    "    # Wrap our cost function so it can e passed to optimize.minimize()\n",
    "    def cost_function_wrapper(self, params, X, y):\n",
    "        self.N.set_params(params)\n",
    "        cost = self.N.cost_function(X, y)\n",
    "        gradient = self.N.compute_gradients(X, y)\n",
    "        return cost, gradient\n",
    "        \n",
    "    # Allows us to track the cost function value as we train network\n",
    "    def callback(self, params):\n",
    "        self.N.set_params(params)\n",
    "        self.J.append(self.N.cost_function(self.X, self.y))\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # Internal variables for callback function:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Make empty list to store costs\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.N.get_params()\n",
    "        \n",
    "        options = {'maxiter': 200, 'disp': True}\n",
    "        \n",
    "        # Optimize accepts:\n",
    "        #    1. Vector of parameters\n",
    "        #    2. Input & output data\n",
    "        # It returns:\n",
    "        #    1. Cost (error measure)\n",
    "        #    2. Gradients (step down)\n",
    "        _res = optimize.minimize(self.cost_function_wrapper, params0, \\\n",
    "                                jac=True, method='BFGS', args=(X, y), \\\n",
    "                                options=options, callback=self.callback)\n",
    "        \n",
    "        # As network is trained, replace original parameters\n",
    "        # with learned parameters\n",
    "        self.N.set_params(_res.x)\n",
    "        self.optimization_results = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 57\n",
      "         Function evaluations: 64\n",
      "         Gradient evaluations: 64\n"
     ]
    }
   ],
   "source": [
    "T = trainer(network)\n",
    "\n",
    "T.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Iterations')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVld/x+3rRvVMROf0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5460f7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can see the cost decrease as we iterate\n",
    "plt.plot(T.J)\n",
    "plt.grid(1)\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.74997186],\n",
       "       [ 0.82003932],\n",
       "       [ 0.93001249]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, if we run our training data through our network...\n",
    "network.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75],\n",
       "       [ 0.82],\n",
       "       [ 0.93]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our predictions are correct!\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But just because it fits our training data, that doesn't mean it's a good fit for the real world...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "Overfitting: It models the training data too well. Noise or randomness in the training data is picked up and learned by the model so that it fails to predict future data correctly.\n",
    "\n",
    "We must consider our process:\n",
    "We train our network based on samples of real world data. For example, we measure that we sleep for 3 hours and study for 5, and get 60 on our test. Does this mean that sleeping for 3 hours and studying for 5 hours would always result in a score of 60? Of course not. There are many other variables too. Variables we didn't measure. Maybe we guessed a few questions and got lucky, or also listened well in lectures.\n",
    "\n",
    "Slightly more formally, we could say:\n",
    "\n",
    "Observations = signal and noise\n",
    "\n",
    "We're interested in interpreting the signal, but there will be some noise obscuring things.\n",
    "\n",
    "\n",
    "Imagine our test:\n",
    "The observation might be, 60 points. Maybe 50 points are due to aptitude (signal), but 10 points are due to luck (noise).\n",
    "\n",
    "So how do we train our model on the signal, and not the noise?\n",
    "\n",
    "Example:\n",
    "Here, due to the data fed in, it looks like studying more will push the score down.\n",
    "\n",
    "<img src=\"images/neural_net_notes/studymore.jpg\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "So how do we know if we're overfitting or not?\n",
    "\n",
    "We split the data into __training data__ and __testing data__.\n",
    "\n",
    "We only feed in training data, and then check it against our testing data.\n",
    "\n",
    "We can compare the testing error (cost) against the training error to see where overfitting occurs.\n",
    "\n",
    "## Fixing overfitting\n",
    "One approach is to just throw more data at it.\n",
    "Rule of thumb: number of examples needed = 10 * degrees of freedom\n",
    "\n",
    "E.g., since we have 9 weights that can change, we need at least 90 observations.\n",
    "\n",
    "Another approach is __regularization__.\n",
    "This involves adding a term to our cost function that penalizes overly complex models _(models with too much noise?)_.\n",
    "\n",
    "Can be done by adding the square of the weights to the cost function, so models with large magnitudes of weights cost more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
